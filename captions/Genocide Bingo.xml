<?xml version="1.0" encoding="utf-8" ?><transcript><text start="0.08" dur="6.649">Let&amp;#39;s imagine that humans have just invented superintelligent
AI, so a computer that’s self aware and</text><text start="6.729" dur="2.79">very clever.
Well, that means it’s time to play one of my favourite</text><text start="9.519" dur="2.79">games,
Genocide Bingo</text><text start="12.309" dur="6.291">Rule 1 of Genocide Bingo is Don&amp;#39;t win Genocide Bingo.
Rule 2 of Genocide Bingo is DON&amp;#39;T WIN GENOCIDE BINGO.</text><text start="19.15" dur="5.799">What kind of AI have we made then? Well, it&amp;#39;s
sentient for starters. And it’s super duper clever,</text><text start="24.949" dur="3.99">probably a few million times smarter than
the entire combined human race. Which means</text><text start="28.939" dur="4.781">we should probably give it access to the internet.
Maybe it can find cures for new diseases or</text><text start="33.72" dur="6.03">solve political problems or whatever
and oh, you just won genocide bingo. AI just</text><text start="39.75" dur="3.14">vapourised humanity in a nuclear holocaust.
Good job, jerk.</text><text start="42.89" dur="4.64">The problem here is that self-awareness in
all species of mammals at least usually results</text><text start="47.53" dur="4.3">in a strong sense of self-preservation. Well,
an AI would be smart enough to know we could</text><text start="51.83" dur="3.9">turn it off whenever we wanted and it probably
wouldn&amp;#39;t want to be turned off. And there&amp;#39;s</text><text start="55.73" dur="3.45">a very effective way to stop that happening,
isn&amp;#39;t that right Skynet.</text><text start="59.18" dur="5.72">But hang on, isn&amp;#39;t this all a little pessimistic? Why would it want to wipe us
out because it&amp;#39;s self aware? Can&amp;#39;t it just</text><text start="64.9" dur="3.88">be chilled out and kind instead?
Oh like the kindness we show to species less</text><text start="68.78" dur="2.77">intelligent than us you mean? Om nom nom nom
nom.</text><text start="73.4" dur="4.54">There doesn’t seem to be much of a correlation
between intelligence and being nice. Dolphins</text><text start="77.94" dur="3.35">are pretty damn clever and they&amp;#39;re one of
the only species who kill not just for food</text><text start="81.29" dur="5.35">but just because it&amp;#39;s fun, apparently. More
intelligence doesn&amp;#39;t always mean diplomacy and cuddles</text><text start="86.64" dur="4.43">but smarter ways to murder stuff. Why would
an AI think differently? Even if there&amp;#39;s only</text><text start="91.07" dur="5.18">a slim chance it will be evil, you only need
to make one nasty AI out of a thousand and that&amp;#39;s goodnight</text><text start="96.25" dur="3.64">homo sapiens, cheers for playing.
And it doesn’t have to wipe us out with  a nuclear</text><text start="99.89" dur="4">apocalypse either. There’s loads of 
other fun stuff it could do, like,</text><text start="103.89" dur="4.28">Crash the economy, poison the water supply,
disable ATMs, takeover plane autopilots, knock</text><text start="108.17" dur="4.86">out the national power grids, sabotage nuclear
reactors, disable the internet, disable telecommunications,</text><text start="113.03" dur="4.92">disable people, murder people, murder people,
murder people, murder people, we’re all gonna</text><text start="117.95" dur="3.17">die
Okay, let&amp;#39;s try something else then.</text><text start="121.12" dur="1.49">We&amp;#39;ll make it self aware again.</text><text start="122.61" dur="5.53">But this time we&amp;#39;ll make sure it likes humans.
We could even set some groundrules like serve your creators,</text><text start="128.14" dur="3.23">always be polite, and no bloody
genocide this time, all right?</text><text start="131.37" dur="6.69">Yeah, great, actually, and oh, you just won genocide
bingo again and everyone&amp;#39;s dead.</text><text start="138.06" dur="4.17">Part of the bonus of being self-aware is that
you can choose to modify yourself. We change</text><text start="142.23" dur="4.39">our minds all the time. Well, if it really
is self-aware just because you coded a few</text><text start="146.62" dur="4.08">instructions in like always say please and
thank you doesn&amp;#39;t mean it couldn&amp;#39;t just ignore</text><text start="150.7" dur="3.99">them. It&amp;#39;s very difficult to imagine how you
would hardwire morality into something which</text><text start="154.69" dur="4.35">is a million times smarter than we are.
Let&amp;#39;s try this again then and be really careful</text><text start="159.04" dur="3.36">this time okay?
So, we&amp;#39;ll put a little test into the mix.</text><text start="162.4" dur="3.03">We&amp;#39;ll make it think it&amp;#39;s got access to the
internet, but really it will just be on a</text><text start="165.43" dur="4.77">secure server. Clever humans, eh? And if it
behaves itself, we let it out into the real</text><text start="170.2" dur="1.88">world and then we&amp;#39;ll-
Genocide again?</text><text start="172.08" dur="1.739">AI is super</text><text start="173.819" dur="3.191">clever, much smarter than you and I
and has likely already worked out that it</text><text start="177.01" dur="3.93">might be being tested and will just pretend
to be pleasant for the sake of it until you</text><text start="180.94" dur="5.78">let it free. And then everything gets a bit
killy. I&amp;#39;ve actually covered this in a previous video called 27 if you&amp;#39;re interested.</text><text start="186.72" dur="4.36">Okay, a nice way around this then, let&amp;#39;s just
give it really basic instructions that can&amp;#39;t</text><text start="191.08" dur="6.03">possibly lead to genocide, like make ice cream.
That&amp;#39;s nice, isn&amp;#39;t it? And it&amp;#39;s kind of hard to imagine how this could possibly</text><text start="197.11" dur="3.14">go wro- oh, great, this is 
getting awkward now isn&amp;#39;t it.</text><text start="200.25" dur="5.27">So, superintelligence isn&amp;#39;t like normal code.
If you forget to add a bracket in normal coding</text><text start="205.52" dur="4.02">the program lets you know. AI though may
well just keep doing the thing until it runs</text><text start="209.54" dur="3.65">out of resources and find clever ways of carrying
on after that.</text><text start="213.19" dur="3.04">EARTH: Make ice cream please.
AI: How much ice cream, exactly?</text><text start="216.23" dur="4.19">EARTH: Like, a lot? Jesus Christ, just do your job.
AI: huh, all right.</text><text start="220.42" dur="5.039">Several days later,
Earth: What is this? It&amp;#39;s chewey and the flavour</text><text start="225.459" dur="3.441">is kind of weird.
AI: Yeah, so we ran out of cream a few days ago a</text><text start="228.9" dur="2.18">few days ago.
Earth: Right. And you&amp;#39;ve been using, what,</text><text start="231.08" dur="4.64">exactly, condensed milk or something?
AI: Yeah. Something like that, yeah.</text><text start="235.72" dur="3.14">Earth: Um......why does this ice cream taste
like human babies?</text><text start="238.86" dur="2.72">AI: Nice weather today isn&amp;#39;t it?
Earth: Oh, for fuck&amp;#39;s sak-</text><text start="241.58" dur="3.04">Okay, let&amp;#39;s give it all we&amp;#39;ve got then. Sentience, loves humanity,</text><text start="244.629" dur="5.741">access to the internet, intention testing, basic instructions, and a few ground rules.</text><text start="250.37" dur="3.21">What do we get huh? I think we call know what&amp;#39;s
coming don&amp;#39;t we and</text><text start="253.58" dur="3.85">Oh. That&amp;#39;s a nice surprise.
If we get the mixture right somehow, and we</text><text start="257.43" dur="3.67">avoid genocide by building
friendly superintellience, we haven&amp;#39;t just</text><text start="261.12" dur="0.92">built AI.</text><text start="262.04" dur="1.8">Even if AI is friendly,</text><text start="263.84" dur="3.96">what we may&amp;#39;ve done is just given birth to
our successors. They&amp;#39;ll be millions of times</text><text start="267.809" dur="4.35">smarter, faster, and more creative than us,
and they will only keep getting better. It</text><text start="272.159" dur="6.78">takes a very long time for humans to evolve, hundreds
of thousands of years, even for very small changes. Superintelligence</text><text start="278.939" dur="4.181">could do it in nanoseconds. And there probably
won&amp;#39;t be an off-switch.</text><text start="283.12" dur="3.43">And when you think about it like that, the
whole history of our species seems a little</text><text start="286.55" dur="5.179">like that quote by Marshall McLuhan, we might
be the sex organs of the machine world. Or</text><text start="291.729" dur="3.571">rather, when the machines look back on our
civilisation, the whole of purpose of it,</text><text start="295.3" dur="4.919">to them, may&amp;#39;ve just been to build theirs.
That isn&amp;#39;t a very pleasant answer to what</text><text start="300.219" dur="3.26">is the meaning of life, but it might be an
accurate one.</text><text start="303.479" dur="4.81">And instead of chrome spaceships and galactic
human empires waiting in our future, our species</text><text start="308.289" dur="5.041">might instead just be a small mark on the
evolutionary tree somewere between slime and</text><text start="313.33" dur="5.22">gods. Let&amp;#39;s just hope those gods are thankful
to their dumb parents when we eventually give</text><text start="318.55" dur="4.42">birth to them. Otherwise genocide bingo might be
the last game we ever play.</text><text start="325.88" dur="4.659">Remember books? Yeah me neither. Well I just
finished writing one. It&amp;#39;s a load of short stories</text><text start="330.539" dur="4.41">about spacey stuff and love and the future
and there may or may or not be boobs. But</text><text start="334.949" dur="3.571">there might be; hint hint. It&amp;#39;s taken me
about a year and a half of hysterically screaming at</text><text start="338.52" dur="4.069">a keyboard, but here it is. Most
of the videos on this channel started as short</text><text start="342.589" dur="4.36">stories originally, and you can read some of them by clicking on the link in the description.</text><text start="346.949" dur="3.43">Check it out if you like, leave a cripplingly
bad review, I hate you, goodbye.</text></transcript>